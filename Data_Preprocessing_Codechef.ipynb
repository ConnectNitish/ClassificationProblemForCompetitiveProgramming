{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:20:13.457564Z",
     "start_time": "2019-04-02T09:20:12.629094Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import wordcloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:45:42.180672Z",
     "start_time": "2019-04-02T09:45:42.173523Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def clean_statement(statement):\n",
    "#     x = re.sub('-', ' ', x)\n",
    "    statement = re.sub('$', ' ', statement)\n",
    "    statement = re.sub('[^A-Za-z]+', ' ', statement)\n",
    "    statement = re.sub('[,|.|?|\\n]|\\t', '', statement)\n",
    "    statement = re.sub('n\\'t', ' ', statement)\n",
    "    statement = re.sub('submission|submissions|Submission|submission|th ', '', statement)\n",
    "    statement = re.sub('one|two|given|need', '', statement)\n",
    "    \n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:20:43.469620Z",
     "start_time": "2019-04-02T09:20:43.461778Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def process_problem_statement(q_statement):\n",
    "    \n",
    "    q_statement = clean_statement(q_statement)\n",
    "    \n",
    "#     q_statement = re.sub('[^A-Za-z]+', ' ', q_statement)\n",
    "    \n",
    "    tokens = word_tokenize(q_statement)\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    \n",
    "    word_list = [i for i in q_statement.lower().split() if i not in stoplist]\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "#     word_list = [ps.stem(word) for word in word_list]\n",
    "    \n",
    "    q_statement = ' '.join(word_list)\n",
    "    \n",
    "#     print(q_statement)\n",
    "    \n",
    "    return q_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:21:05.786951Z",
     "start_time": "2019-04-02T09:21:05.778104Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_problem_solution(solution):\n",
    "    \n",
    "#     solution = clean_statement(solution)\n",
    "    \n",
    "    tokens = word_tokenize(solution)\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    \n",
    "    word_list = [i for i in solution.lower().split() if i not in stoplist]\n",
    "    \n",
    "#     ps = PorterStemmer()\n",
    "    \n",
    "#     word_list = [ps.stem(word) for word in word_list]\n",
    "    \n",
    "    solution = ' '.join(word_list)\n",
    "    \n",
    "#     print(q_statement)\n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:21:36.593788Z",
     "start_time": "2019-04-02T09:21:36.581980Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_tags(tag_col):\n",
    "    \n",
    "#     print(tag_col)\n",
    "#     tags_present = list(re.split(',',tag_col))\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    word_list = [i for i in solution.lower().split() if i not in stoplist]\n",
    "    \n",
    "    tags_set = set(tags_present)\n",
    "    tags_diff = tags_set.difference(set(all_tags_list))\n",
    "    \n",
    "    new_set = tags_set.difference(tags_diff)\n",
    "#     print(new_set)\n",
    "    return list(new_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:21:48.678160Z",
     "start_time": "2019-04-02T09:21:48.670250Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_distinct_tags(tags_col):\n",
    "    \n",
    "    tags_list = []\n",
    "    \n",
    "    t_sets = set(tags_list)\n",
    "    \n",
    "    for row in tags_col:\n",
    "#         print(row)\n",
    "        t_list = re.split(',',row)\n",
    "#         print(t_list)\n",
    "        t_sets = t_sets.union(set(t_list))\n",
    "#         print(t_sets)\n",
    "    tags_list = list(t_sets)\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'))\n",
    "    \n",
    "    word_list = [i for i in tags_list if i not in stoplist]\n",
    "    \n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:43:56.505389Z",
     "start_time": "2019-04-02T09:43:56.500256Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_problem_Languages(lang_col):\n",
    "    \n",
    "    lang_col = clean_statement(lang_col)\n",
    "    \n",
    "    return lang_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = ['dsu', 'trees', 'chinese remainder theorem', 'sortings', 'games', 'implementation', 'bitmasks',\n",
    "              '*special', 'hashing', 'geometry', 'two pointers', 'combinatorics', 'flows', 'strings',\n",
    "              'probabilities', 'data structures', 'ternary search', 'greedy', 'math', 'matrices',\n",
    "              'divide and conquer', 'dfs and similar', 'constructive algorithms', 'brute force', 'dp',\n",
    "              '2-sat', 'graph matchings', 'binary search', 'number theory', 'graphs', 'fft', 'shortest paths',\n",
    "              'schedules', 'meet-in-the-middle', 'string suffix structures', 'expression parsing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tags(tags):\n",
    "    tags = eval(tags)\n",
    "    i = 0\n",
    "    while i<len(tags):\n",
    "#         print(len(tags))\n",
    "        if tags[i] not in tags_list:\n",
    "            tags.remove(tags[i])\n",
    "            continue\n",
    "        i += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "tags = \"['anton_lunyov', '2-sat', 'cook06', 'dsu', 'easy']\"\n",
    "tags = validate_tags(tags)\n",
    "tags = str(tags)\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:47:28.229959Z",
     "start_time": "2019-04-02T09:47:28.190518Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    \n",
    "#     df = pd.read_csv(\"codechef_question_v1.csv\")\n",
    "    df = pd.read_csv(\"AllDetails_WithSubmIssionID_nitish.csv\")\n",
    "    df = df.drop(['QuestionCode','Title','Questionlink'],axis = 1)\n",
    "    \n",
    "    df[\"Languages\"] = [process_problem_Languages(x) for x in df[\"Languages\"]]\n",
    "    df = df[df[\"Languages\"].str.match(\"C\") == True]\n",
    "    \n",
    "    \n",
    "    global distinct_tags\n",
    "#     return df\n",
    "    for index, row in df.iterrows():\n",
    "#         print(index, row['Tags'])\n",
    "        tags = validate_tags(row['Tags'])\n",
    "        if tags == []:\n",
    "            df.drop(index, inplace=True)\n",
    "        else:\n",
    "#             df.iloc[index,3] = str(tags)\n",
    "            df.at[index, 'Tags'] = str(tags)\n",
    "        \n",
    "    \n",
    "    print(df[\"Tags\"])    \n",
    "        \n",
    "#     distinct_tags = get_all_distinct_tags(df[\"tags\"])\n",
    "    \n",
    "#     print(df.columns)\n",
    "#     print(df.head)\n",
    "#     print(distinct_tags)\n",
    "    \n",
    "#     print(df[\"Languages\"])\n",
    "    \n",
    "#     df[\"problem statement\"] = [process_problem_statement(x) for x in df[\"problem statement\"]]\n",
    "#     df[\"solution\"] = [process_problem_solution(x) for x in df[\"solution\"]]\n",
    "#     df[\"time_taken\"] = [process_time_taken(x) for x in df[\"time_taken\"]]\n",
    "    \n",
    "#     X = copy.deepcopy(df[\"solution\"])\n",
    "#     Y = [process_tags(distinct_tags,x) for x in df[\"tags\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "# #     print()\n",
    "# #     print(X)\n",
    "# #     print()\n",
    "# #     print(Y)\n",
    "# #     print()\n",
    "    \n",
    "# #     print(type(X))\n",
    "    \n",
    "#     X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "# #     print(type(X_train))\n",
    "# #     print(X_train.shape)\n",
    "    \n",
    "#     return X_train, X_validation, Y_train, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:47:29.045750Z",
     "start_time": "2019-04-02T09:47:29.007433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2956      ['greedy', 'implementation']\n",
      "2957      ['greedy', 'implementation']\n",
      "2958      ['greedy', 'implementation']\n",
      "2959      ['greedy', 'implementation']\n",
      "2960      ['greedy', 'implementation']\n",
      "2961      ['greedy', 'implementation']\n",
      "2962      ['greedy', 'implementation']\n",
      "2963      ['greedy', 'implementation']\n",
      "2964      ['greedy', 'implementation']\n",
      "2965      ['greedy', 'implementation']\n",
      "2966      ['greedy', 'implementation']\n",
      "2967      ['greedy', 'implementation']\n",
      "2968      ['greedy', 'implementation']\n",
      "2969      ['greedy', 'implementation']\n",
      "2970      ['greedy', 'implementation']\n",
      "2971      ['greedy', 'implementation']\n",
      "2972      ['greedy', 'implementation']\n",
      "2973      ['greedy', 'implementation']\n",
      "2974      ['greedy', 'implementation']\n",
      "2975      ['greedy', 'implementation']\n",
      "2976      ['greedy', 'implementation']\n",
      "2977      ['greedy', 'implementation']\n",
      "2978      ['greedy', 'implementation']\n",
      "2979      ['greedy', 'implementation']\n",
      "2981      ['greedy', 'implementation']\n",
      "2982      ['greedy', 'implementation']\n",
      "2983      ['greedy', 'implementation']\n",
      "2984      ['greedy', 'implementation']\n",
      "2985      ['greedy', 'implementation']\n",
      "2986      ['greedy', 'implementation']\n",
      "                      ...             \n",
      "137607                     ['hashing']\n",
      "137609                     ['hashing']\n",
      "137610                     ['hashing']\n",
      "137611                     ['hashing']\n",
      "137613                     ['hashing']\n",
      "137614                     ['hashing']\n",
      "137615                     ['hashing']\n",
      "137616                     ['hashing']\n",
      "137617                     ['hashing']\n",
      "137620                     ['hashing']\n",
      "137621                     ['hashing']\n",
      "137622                     ['hashing']\n",
      "137623                     ['hashing']\n",
      "137624                     ['hashing']\n",
      "137625                     ['hashing']\n",
      "137626                     ['hashing']\n",
      "137629                     ['hashing']\n",
      "137630                     ['hashing']\n",
      "137631                     ['hashing']\n",
      "137632                     ['hashing']\n",
      "137633                     ['hashing']\n",
      "137634                     ['hashing']\n",
      "137636                     ['hashing']\n",
      "137638                     ['hashing']\n",
      "137639                     ['hashing']\n",
      "137640                     ['hashing']\n",
      "137641                     ['hashing']\n",
      "137643                     ['hashing']\n",
      "137645                     ['hashing']\n",
      "137646                     ['hashing']\n",
      "Name: Tags, Length: 10813, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_preprocessing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
